{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Parallel Face Recognition System","text":"<p>Welcome to the documentation for the Parallel Face Recognition System, a project designed to compare and optimize face matching using both serial and parallel processing techniques in Python.</p> <p>This system uses multiprocessing to improve performance when searching and matching faces across image datasets, while also providing a serial baseline for benchmarking and analysis.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Parallel and serial implementations for face search  </li> <li>Smart worker allocation based on CPU and workload  </li> <li>Caching system to avoid redundant face encoding  </li> <li>Benchmarking tools for performance comparison  </li> <li>Efficient image dataset processing  </li> </ul>"},{"location":"#purpose-of-the-project","title":"Purpose of the Project","text":"<p>The goal of this project is to show how parallel computing can significantly reduce execution time for computationally expensive tasks such as face recognition, and to provide a clean, reusable API for experimentation and learning.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Use the navigation menu to explore the API reference for each module:</p> <ul> <li><code>benchmark</code> \u2014 Performance measurement utilities  </li> <li><code>utils</code> \u2014 Helper functions and cache system  </li> <li><code>parallel_face_search</code> \u2014 Multiprocessing implementation  </li> <li><code>serial_face_search</code> \u2014 Sequential implementation  </li> <li><code>main</code> \u2014 Entry point and orchestration  </li> </ul>"},{"location":"benchmark/","title":"Benchmark Module","text":""},{"location":"benchmark/#benchmark","title":"benchmark","text":"<p>Benchmark parallel vs serial implementation Demonstrates speedup achieved</p>"},{"location":"benchmark/#benchmark.compare_performance","title":"compare_performance","text":"<pre><code>compare_performance(find_all=True)\n</code></pre> <p>Compare serial vs parallel performance</p> Source code in <code>benchmark.py</code> <pre><code>def compare_performance(find_all=True):\n    \"\"\"Compare serial vs parallel performance\"\"\"\n    print(\"-----------------------------------------------------------\")\n    print(\"        Performance comparison: Serial vs Parallel\")\n    print(\"-----------------------------------------------------------\\n\")\n\n    known_image = \"dataset/max.jpg\"\n    image_folder = \"dataset/imageset/\"\n\n    # Serial\n    serial_matches, serial_time = run_serial(known_image, image_folder, find_all)\n\n    # Parallel (auto-detect workers)\n    parallel_matches, parallel_time, actual_workers = run_parallel(\n        known_image,\n        image_folder,\n        num_workers=None,\n        find_all=find_all,\n        verbose=True\n    )\n\n    print(\"\\nAnalysis:\")\n    speedup = serial_time / parallel_time if parallel_time &gt; 0 else 0\n    efficiency = (speedup / actual_workers) * 100 if actual_workers &gt; 0 else 0\n\n    print(f\"Serial Time:     {format_time(serial_time)}\")\n    print(f\"Parallel Time:   {format_time(parallel_time)}\")\n    print(f\"Speedup:         {speedup:.2f}x\")\n    print(f\"Efficiency:      {efficiency:.1f}%\")\n    print(f\"Workers Used:    {actual_workers}\")\n\n    print(\"\\nInterpretation:\")\n    if efficiency &gt;= 80:\n        print(f\"Excellent efficiency ({efficiency:.1f}%)\")\n    elif efficiency &gt;= 60:\n        print(f\"Good efficiency ({efficiency:.1f}%)\")\n    elif efficiency &gt;= 40:\n        print(f\"Moderate efficiency ({efficiency:.1f}%)\")\n    else:\n        print(f\"Low efficiency ({efficiency:.1f}%)\")\n\n    # Correctness check\n    if set(serial_matches) == set(parallel_matches):\n        print(\"\\nResults match! Parallel implementation is correct.\")\n    else:\n        print(\"\\nResults differ between serial and parallel!\")\n        print(f\"Serial found:   {len(serial_matches)} matches\")\n        print(f\"Parallel found: {len(parallel_matches)} matches\")\n</code></pre>"},{"location":"benchmark/#benchmark.run_parallel","title":"run_parallel","text":"<pre><code>run_parallel(\n    known_image_path,\n    folder_path,\n    num_workers,\n    find_all=True,\n    verbose=True,\n)\n</code></pre> <p>Run parallel face recognition</p> <p>Returns:</p> Type Description <p>matches, time_taken, actual_workers</p> Source code in <code>benchmark.py</code> <pre><code>def run_parallel(known_image_path, folder_path, num_workers, find_all=True, verbose=True):\n    \"\"\"\n    Run parallel face recognition\n\n    Returns:\n        matches, time_taken, actual_workers\n    \"\"\"\n    if verbose:\n        print(f\"\\nRunning parallel implementation...\")\n\n    start_time = time.time()\n\n    recognizer = ParallelFaceRecognize(known_image_path, num_workers=num_workers, verbose=verbose)\n    recognizer.load_known_face()\n\n    matches = recognizer.search_parallel(folder_path, find_all=find_all)\n\n    time_taken = time.time() - start_time\n\n    if verbose:\n        print(f\"\\nParallel Results:\")\n        print(f\"Time taken: {time_taken:.2f}s\")\n        print(f\"Matches found: {len(matches)}\")\n\n    return matches, time_taken, recognizer.num_workers\n</code></pre>"},{"location":"benchmark/#benchmark.run_serial","title":"run_serial","text":"<pre><code>run_serial(known_image_path, folder_path, find_all=True)\n</code></pre> <p>Run serial face recognition</p> <p>Returns:</p> Type Description <p>matches, time_taken</p> Source code in <code>benchmark.py</code> <pre><code>def run_serial(known_image_path, folder_path, find_all=True):\n    \"\"\"\n    Run serial face recognition\n\n    Returns:\n        matches, time_taken\n    \"\"\"\n    print(\"Running serial implementation...\")\n\n    matches, time_taken = serial_face_recognition(\n        known_image_path,\n        folder_path,\n        find_all=find_all,\n        save_results=False\n    )\n\n    print(f\"\\nSerial Results:\")\n    print(f\"Time taken: {time_taken:.2f}s\")\n    print(f\"Matches found: {len(matches)}\")\n\n    return matches, time_taken\n</code></pre>"},{"location":"benchmark/#benchmark.test_find_all_vs_first","title":"test_find_all_vs_first","text":"<pre><code>test_find_all_vs_first()\n</code></pre> <p>Compare find-all vs find-first performance</p> Source code in <code>benchmark.py</code> <pre><code>def test_find_all_vs_first():\n    \"\"\"Compare find-all vs find-first performance\"\"\"\n    print(\"\\nComparison: Find All vs Find First Match\\n\")\n\n    known_image = \"dataset/max.jpg\"\n    image_folder = \"dataset/imageset/\"\n\n    # Find all\n    print(\"Finding ALL matches\")\n    matches_all, time_all, _ = run_parallel(known_image, image_folder, num_workers=4, \n                                             find_all=True, verbose=False)\n    print(f\"Found {len(matches_all)} matches in {time_all:.2f}s\\n\")\n\n    # Find first\n    print(\"Finding first match only\")\n    matches_first, time_first, _ = run_parallel(known_image, image_folder, num_workers=4, \n                                                  find_all=False, verbose=False)\n    print(f\"Found {len(matches_first)} match in {time_first:.2f}s\\n\")\n\n    # Analysis\n    print(\"Analysis:\")\n    if time_first &lt; time_all:\n        speedup = time_all / time_first\n        saved = (1 - time_first / time_all) * 100\n        print(f\"Early termination saved {saved:.1f}% time\")\n        print(f\"Find first: {time_first:.2f}s\")\n        print(f\"Find all:   {time_all:.2f}s\")\n        print(f\"Speedup:    {speedup:.2f}x\")\n    else:\n        print(\"No significant difference (match found very early)\")\n</code></pre>"},{"location":"benchmark/#benchmark.test_scalability","title":"test_scalability","text":"<pre><code>test_scalability(workers_list=None)\n</code></pre> <p>Test how performance scales with number of workers</p> Source code in <code>benchmark.py</code> <pre><code>def test_scalability(workers_list=None):\n    \"\"\"Test how performance scales with number of workers\"\"\"\n    if workers_list is None:\n        cpu_count = mp.cpu_count()\n        workers_list = [1, 2, 4, min(8, cpu_count), cpu_count, cpu_count * 2]\n        workers_list = sorted(set(workers_list))\n\n    print(\"\\nScalability test: Performance vs Worker Count\\n\")\n\n    known_image = \"dataset/max.jpg\"\n    image_folder = \"dataset/imageset/\"\n\n    results = []\n\n    for num_workers in workers_list:\n        print(f\"Testing with {num_workers} worker(s)...\")\n\n        recognizer = ParallelFaceRecognize(known_image, num_workers=num_workers, verbose=False)\n        recognizer.load_known_face()\n\n        start = time.time()\n        matches = recognizer.search_parallel(image_folder)\n        elapsed = time.time() - start\n\n        results.append({\n            'workers': num_workers,\n            'time': elapsed,\n            'matches': len(matches)\n        })\n\n        print(f\"Time: {elapsed:.2f}s | Matches: {len(matches)}\\n\")\n\n    # Summary table\n    print(\"Scalability summary\")\n    print(f\"{'Workers':&lt;10} {'Time (s)':&lt;12} {'Speedup':&lt;12} {'Efficiency':&lt;12}\")\n    print(\"-\" * 46)\n\n    baseline_time = results[0]['time']\n\n    for r in results:\n        speedup = baseline_time / r['time'] if r['time'] &gt; 0 else 0\n        efficiency = (speedup / r['workers']) * 100 if r['workers'] &gt; 0 else 0\n        print(f\"{r['workers']:&lt;10} {r['time']:&lt;12.2f} {speedup:&lt;12.2f} {efficiency:&lt;12.1f}%\")\n</code></pre>"},{"location":"main/","title":"Main Entry Point","text":""},{"location":"main/#main","title":"main","text":"<p>Main entry point for parallel face recognition with caching</p>"},{"location":"main/#main.main","title":"main","text":"<pre><code>main()\n</code></pre> <p>Main execution function</p> Source code in <code>main.py</code> <pre><code>def main():\n    \"\"\"\n    Main execution function\n    \"\"\"\n    print(\"-------------------------------------------\")\n    print(\"Parallel face recognition\")\n    print(\"-------------------------------------------\\n\")\n\n    # image paths\n    known_image = \"dataset/max.jpg\"\n    image_folder = \"dataset/imageset/\"\n\n    # initialize parallel recognizer\n    recognizer = ParallelFaceRecognize(known_image)\n    recognizer.load_known_face()\n\n    # get image files\n    print(\"\\nScanning image folder...\")\n    filenames = recognizer.get_image_files(image_folder)\n    print(f\"Found {len(filenames)} images to process\")\n\n    # calculate no. of workers\n    if recognizer.num_workers is None:\n        from utils import calculate_optimal_workers\n        recognizer.num_workers = calculate_optimal_workers(len(filenames))\n    print(f\"Using {recognizer.num_workers} worker processes\")\n    print(f\"System detected {mp.cpu_count()} logical CPU threads\")\n\n    # parallel search\n    print(\"\\nSearching for matching faces (parallel mode)...\")\n    start_time = time.time()\n\n    matches = recognizer.search_parallel(image_folder)\n\n    parallel_time = time.time() - start_time\n\n    # display results\n    print(\"\\nProcessing results...\")\n\n    if matches:\n        print(f\"\\nMatches found in {len(matches)} image(s):\")\n        for i, filename in enumerate(matches, 1):\n            print(f\"{i}. {filename}\")\n\n        # save found images with rectangles with caching\n        print(f\"\\nSaving results to 'found_by_parallel/' directory...\")\n        save_start = time.time()\n        save_found_images(matches, image_folder, recognizer.known_encoding, use_cache=True)\n        save_time = time.time() - save_start\n\n        print(f\"\\nImages saved in {save_time:.2f} seconds\")\n\n    else:\n        print(\"\\nNo matches found\")\n\n    # performance metrics\n    print(\"\\nPerformance metrics:\")\n    print(f\"Search time: {parallel_time:.2f} seconds\")\n    print(f\"Workers used: {recognizer.num_workers}\")\n    print(f\"Images per worker: ~{len(filenames) // recognizer.num_workers}\")\n    print(f\"Average time per image: {parallel_time / len(filenames):.3f} seconds\")\n\n    print(\"\\nTip: Run again to see cache speedup!\")\n    print(\"Run 'python benchmark.py' to compare with serial performance\")\n</code></pre>"},{"location":"main/#main.save_found_images","title":"save_found_images","text":"<pre><code>save_found_images(\n    matches,\n    folder_path,\n    known_encoding,\n    output_dir=\"found_by_parallel\",\n    use_cache=True,\n)\n</code></pre> <p>Save found image with rectangle (bounding box) around detected face Rectangle will apply only to the target face</p> <p>Parameters:</p> Name Type Description Default <code>matches</code> <p>list of matched filenames</p> required <code>folder_path</code> <p>source folder path</p> required <code>known_encoding</code> <p>encoded known face</p> required <code>output_dir</code> <p>directory to save results</p> <code>'found_by_parallel'</code> <code>use_cache</code> <p>whether to use caching (default True)</p> <code>True</code> Explanation <p>Cache stores face locations and encodings to avoid recomputation Speeds up repeated runs significantly</p> Source code in <code>main.py</code> <pre><code>def save_found_images(matches, folder_path, known_encoding, output_dir=\"found_by_parallel\", use_cache=True):\n    \"\"\"\n    Save found image with rectangle (bounding box) around detected face\n    Rectangle will apply only to the target face\n\n    Args:\n        matches: list of matched filenames\n        folder_path: source folder path\n        known_encoding: encoded known face\n        output_dir: directory to save results\n        use_cache: whether to use caching (default True)\n\n    Explanation:\n        Cache stores face locations and encodings to avoid recomputation\n        Speeds up repeated runs significantly\n    \"\"\"\n    # create output directory if doesn't exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n        print(f\"Created directory: {output_dir}\")\n\n    # initialize cache\n    cache = FaceCache() if use_cache else None\n\n    cache_hits = 0\n    cache_misses = 0\n\n    print(f\"Processing {len(matches)} matched images...\")\n    for filename in matches:\n        try:\n            image_path = os.path.join(folder_path, filename)\n\n            # try to get from cache first\n            cached_data = cache.get(image_path) if cache else None\n\n            if cached_data:\n                # cache hit - use cached data\n                face_locations = cached_data['locations']\n                face_encodings = cached_data['encodings']\n                cache_hits += 1\n\n                # still need to load image for drawing\n                image = face_recognition.load_image_file(image_path)\n            else:\n                # cache miss - compute and cache\n                image = face_recognition.load_image_file(image_path)\n                face_locations = face_recognition.face_locations(image)\n                face_encodings = face_recognition.face_encodings(image, face_locations)\n\n                # store in cache for next time\n                if cache:\n                    cache.set(image_path, face_locations, face_encodings)\n                cache_misses += 1\n\n            # convert RGB (face_recognition) to BGR (OpenCV)\n            output_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n\n            # loop through each face found in the image\n            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n                # check if this specific face matches the known target\n                matches_target = face_recognition.compare_faces([known_encoding], face_encoding)\n\n                # only draw if this specific face is the one we want\n                if matches_target[0]: # if it's a match\n                    cv2.rectangle(output_image, (left, top), (right, bottom), (0, 255, 0), 2)\n                    # add a label\n                    cv2.putText(output_image, \"MATCH\", (left, top - 10), \n                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n            save_path = os.path.join(output_dir, f\"found_{filename}\")\n            cv2.imwrite(save_path, output_image)\n\n        except Exception as e:\n            print(f\"  Error saving {filename}: {e}\")\n\n    # print cache statistics\n    if use_cache:\n        total = cache_hits + cache_misses\n        hit_rate = (cache_hits / total * 100) if total &gt; 0 else 0\n        print(f\"\\nCache Statistics:\")\n        print(f\"Cache hits: {cache_hits}/{total} ({hit_rate:.1f}%)\")\n        print(f\"Cache misses: {cache_misses}/{total}\")\n        if cache_hits &gt; 0:\n            print(f\"Caching saved a lot of computation time!\")\n</code></pre>"},{"location":"parallel_face_search/","title":"Parallel Face Search","text":""},{"location":"parallel_face_search/#parallel_face_search","title":"parallel_face_search","text":"<p>Parallel Face Recognition using multiprocessing Uses utility functions</p>"},{"location":"parallel_face_search/#parallel_face_search.ParallelFaceRecognize","title":"ParallelFaceRecognize","text":"<p>Parallel face recognition using process pool</p> <p>Time Complexity: O(n/p) where n = images, p = processes Space Complexity: O(n) for image data</p> <p>Key Concept: Data Decomposition (from Flynn's Taxonomy - MIMD) Each worker processes a different subset of images independently</p> Source code in <code>parallel_face_search.py</code> <pre><code>class ParallelFaceRecognize:\n    \"\"\"\n    Parallel face recognition using process pool\n\n    Time Complexity: O(n/p) where n = images, p = processes\n    Space Complexity: O(n) for image data\n\n    Key Concept: Data Decomposition (from Flynn's Taxonomy - MIMD)\n    Each worker processes a different subset of images independently\n    \"\"\"\n\n    def __init__(self, known_image_path, num_workers=None, verbose=True):\n        \"\"\"\n        Initialize recognizer\n\n        Args:\n            known_image_path: path to known face image\n            num_workers: number of worker processes (None = auto-detect)\n            verbose: to print loading messages or not\n        \"\"\"\n        if not validate_image_path(known_image_path):\n            raise ValueError(f\"Invalid known image path: {known_image_path}\")\n\n        self.known_image_path = known_image_path\n        self.known_encoding = None\n        self.num_workers = num_workers\n        self.verbose = verbose\n\n    def load_known_face(self):\n        \"\"\"\n        Load and encode the known face\n\n        Time: O(1) - done once\n\n        Explanation:\n            Done only once in the main process, then shared (read-only) with all workers\n        \"\"\"\n        if self.verbose:\n            print(f\"Loading known face from: {self.known_image_path}\")\n\n        known_image = face_recognition.load_image_file(self.known_image_path)\n        encodings = face_recognition.face_encodings(known_image)\n\n        if not encodings:\n            raise ValueError(\"No face found in known image!\")\n\n        self.known_encoding = encodings[0]\n\n        if self.verbose:\n            print(\"Known face loaded successfully\")\n\n\n    def get_image_files(self, folder_path):\n        \"\"\"\n        Get list of all image files in folder\n\n        Returns:\n            List of image filenames\n        \"\"\"\n        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n\n        filenames = []\n        for file in os.scandir(folder_path):\n            if file.is_file():\n                _, ext = os.path.splitext(file.name.lower())\n                if ext in valid_extensions:\n                    filenames.append(file.name)\n\n        return filenames\n\n    def search_parallel(self, folder_path, find_all=True):\n        \"\"\"\n        Search for matching faces in parallel\n\n        Args:\n            folder_path: directory containing images\n            find_all: if True, find all matches; if False, stop at first match\n\n        Returns:\n            List of filenames with matching faces\n\n        Explanation:\n            Heart of parallel processing\n            1. create chunks aka data decomposition\n            2. spawn worker pool\n            3. map chunks to workers\n            4. collect results\n\n            Uses multiprocessing.Pool which implements MIMD (Multiple Instruction Multiple Data) from Flynn's Taxonomy\n        \"\"\"\n\n        # get all image files\n        filenames = self.get_image_files(folder_path)\n\n        if not filenames:\n            print(\"No image files found!\")\n            return []\n\n        # calculate optimal workers based on workload\n        if self.num_workers is None:\n            self.num_workers = calculate_optimal_workers(\n                total_files=len(filenames)\n            )\n\n        # create chunks for workers\n        chunks = chunk_list(filenames, self.num_workers)\n\n        if self.verbose:\n            print(f\"\\nProcessing {len(filenames)} images with {self.num_workers} workers\")\n            print(f\"Chunk sizes: {[len(chunk) for chunk in chunks]}\")\n\n        # create process pool and process chunks in parallel\n        with mp.Pool(processes=self.num_workers) as pool:\n            # use partial to fix folder_path argument\n            process_func = partial(\n                self._process_chunk, \n                folder_path=folder_path,\n                find_all=find_all\n            )\n\n            # map chunks to workers (parallel execution)\n            # use imap to track progress by chunks\n            results = []\n            with tqdm(total=len(chunks), desc=\"Processing Chunks\", disable=not self.verbose) as pbar:\n                for result in pool.imap(process_func, chunks):\n                    results.append(result)\n                    pbar.update(1)\n\n        # flatten results from all workers\n        matches = []\n        for worker_matches in results:\n            matches.extend(worker_matches)\n\n        return matches\n\n    def _process_chunk(self, chunk, folder_path, find_all=True):\n        \"\"\"\n        Process a chunk of images (runs in worker process)\n\n        Args:\n            chunk: list of filenames to process\n            folder_path: directory containing images\n            find_all: if True, process all images; if False, stop at first match\n\n        Returns:\n            List of matched filenames\n\n        Explanation:\n            This runs in parallel in separate processes\n            Each process has its own copy of Python Interpreter to avoid GIL\n        \"\"\"\n        matches = []\n\n        for filename in chunk:\n            result = self._process_single_image(filename, folder_path)\n            if result:\n                matches.append(filename)\n\n                # early exit if only need the first match\n                if not find_all:\n                    break\n\n        return matches\n\n    def _process_single_image(self, filename, folder_path):\n        \"\"\"\n        Process single image for face matching\n\n        Time: O(1) per image\n        Space: O(1)\n\n        Returns:\n            filename if match found, None otherwise\n\n        Explanation:\n            Early exit optimization: returns immediately on first match.\n            No need to check remaining faces in same image.\n        \"\"\"\n        try:\n            image_path = os.path.join(folder_path, filename)\n            unknown_image = face_recognition.load_image_file(image_path)\n\n            # get all face encodings in this image\n            unknown_encodings = face_recognition.face_encodings(unknown_image)\n\n            # no faces found\n            if not unknown_encodings:\n                return None\n\n            # check each face (early exit on first match)\n            for unknown_encoding in unknown_encodings:\n                matches = face_recognition.compare_faces(\n                    [self.known_encoding], \n                    unknown_encoding\n                )\n\n                if matches[0]:  # match found!\n                    return filename\n\n            return None\n\n        except Exception as e:\n            if self.verbose:\n                print(f\"Error processing {filename}: {e}\")\n            return None\n</code></pre>"},{"location":"parallel_face_search/#parallel_face_search.ParallelFaceRecognize.__init__","title":"__init__","text":"<pre><code>__init__(known_image_path, num_workers=None, verbose=True)\n</code></pre> <p>Initialize recognizer</p> <p>Parameters:</p> Name Type Description Default <code>known_image_path</code> <p>path to known face image</p> required <code>num_workers</code> <p>number of worker processes (None = auto-detect)</p> <code>None</code> <code>verbose</code> <p>to print loading messages or not</p> <code>True</code> Source code in <code>parallel_face_search.py</code> <pre><code>def __init__(self, known_image_path, num_workers=None, verbose=True):\n    \"\"\"\n    Initialize recognizer\n\n    Args:\n        known_image_path: path to known face image\n        num_workers: number of worker processes (None = auto-detect)\n        verbose: to print loading messages or not\n    \"\"\"\n    if not validate_image_path(known_image_path):\n        raise ValueError(f\"Invalid known image path: {known_image_path}\")\n\n    self.known_image_path = known_image_path\n    self.known_encoding = None\n    self.num_workers = num_workers\n    self.verbose = verbose\n</code></pre>"},{"location":"parallel_face_search/#parallel_face_search.ParallelFaceRecognize.get_image_files","title":"get_image_files","text":"<pre><code>get_image_files(folder_path)\n</code></pre> <p>Get list of all image files in folder</p> <p>Returns:</p> Type Description <p>List of image filenames</p> Source code in <code>parallel_face_search.py</code> <pre><code>def get_image_files(self, folder_path):\n    \"\"\"\n    Get list of all image files in folder\n\n    Returns:\n        List of image filenames\n    \"\"\"\n    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n\n    filenames = []\n    for file in os.scandir(folder_path):\n        if file.is_file():\n            _, ext = os.path.splitext(file.name.lower())\n            if ext in valid_extensions:\n                filenames.append(file.name)\n\n    return filenames\n</code></pre>"},{"location":"parallel_face_search/#parallel_face_search.ParallelFaceRecognize.load_known_face","title":"load_known_face","text":"<pre><code>load_known_face()\n</code></pre> <p>Load and encode the known face</p> <p>Time: O(1) - done once</p> Explanation <p>Done only once in the main process, then shared (read-only) with all workers</p> Source code in <code>parallel_face_search.py</code> <pre><code>def load_known_face(self):\n    \"\"\"\n    Load and encode the known face\n\n    Time: O(1) - done once\n\n    Explanation:\n        Done only once in the main process, then shared (read-only) with all workers\n    \"\"\"\n    if self.verbose:\n        print(f\"Loading known face from: {self.known_image_path}\")\n\n    known_image = face_recognition.load_image_file(self.known_image_path)\n    encodings = face_recognition.face_encodings(known_image)\n\n    if not encodings:\n        raise ValueError(\"No face found in known image!\")\n\n    self.known_encoding = encodings[0]\n\n    if self.verbose:\n        print(\"Known face loaded successfully\")\n</code></pre>"},{"location":"parallel_face_search/#parallel_face_search.ParallelFaceRecognize.search_parallel","title":"search_parallel","text":"<pre><code>search_parallel(folder_path, find_all=True)\n</code></pre> <p>Search for matching faces in parallel</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <p>directory containing images</p> required <code>find_all</code> <p>if True, find all matches; if False, stop at first match</p> <code>True</code> <p>Returns:</p> Type Description <p>List of filenames with matching faces</p> Explanation <p>Heart of parallel processing 1. create chunks aka data decomposition 2. spawn worker pool 3. map chunks to workers 4. collect results</p> <p>Uses multiprocessing.Pool which implements MIMD (Multiple Instruction Multiple Data) from Flynn's Taxonomy</p> Source code in <code>parallel_face_search.py</code> <pre><code>def search_parallel(self, folder_path, find_all=True):\n    \"\"\"\n    Search for matching faces in parallel\n\n    Args:\n        folder_path: directory containing images\n        find_all: if True, find all matches; if False, stop at first match\n\n    Returns:\n        List of filenames with matching faces\n\n    Explanation:\n        Heart of parallel processing\n        1. create chunks aka data decomposition\n        2. spawn worker pool\n        3. map chunks to workers\n        4. collect results\n\n        Uses multiprocessing.Pool which implements MIMD (Multiple Instruction Multiple Data) from Flynn's Taxonomy\n    \"\"\"\n\n    # get all image files\n    filenames = self.get_image_files(folder_path)\n\n    if not filenames:\n        print(\"No image files found!\")\n        return []\n\n    # calculate optimal workers based on workload\n    if self.num_workers is None:\n        self.num_workers = calculate_optimal_workers(\n            total_files=len(filenames)\n        )\n\n    # create chunks for workers\n    chunks = chunk_list(filenames, self.num_workers)\n\n    if self.verbose:\n        print(f\"\\nProcessing {len(filenames)} images with {self.num_workers} workers\")\n        print(f\"Chunk sizes: {[len(chunk) for chunk in chunks]}\")\n\n    # create process pool and process chunks in parallel\n    with mp.Pool(processes=self.num_workers) as pool:\n        # use partial to fix folder_path argument\n        process_func = partial(\n            self._process_chunk, \n            folder_path=folder_path,\n            find_all=find_all\n        )\n\n        # map chunks to workers (parallel execution)\n        # use imap to track progress by chunks\n        results = []\n        with tqdm(total=len(chunks), desc=\"Processing Chunks\", disable=not self.verbose) as pbar:\n            for result in pool.imap(process_func, chunks):\n                results.append(result)\n                pbar.update(1)\n\n    # flatten results from all workers\n    matches = []\n    for worker_matches in results:\n        matches.extend(worker_matches)\n\n    return matches\n</code></pre>"},{"location":"serial_face_search/","title":"Serial Face Search","text":""},{"location":"serial_face_search/#serial_face_search","title":"serial_face_search","text":"<p>To install face_recognition, simply use 'pip install face_recognition' in a terminal However, often you may meet an error about the 'dlib' library with cmake. The easy solution is to visit https://github.com/z-mahmud22/Dlib_Windows_Python3.x and download the  compiled wheels locally with the python version, and install it from local</p> <p>if you want to show the found image with the known face, you need opencv and also uncomment the related code.</p>"},{"location":"serial_face_search/#serial_face_search.serial_face_recognition","title":"serial_face_recognition","text":"<pre><code>serial_face_recognition(\n    known_image_path,\n    folder_path,\n    find_all=True,\n    save_results=False,\n)\n</code></pre> <p>Provided logic wrapped in a function for benchmarking.</p> Source code in <code>serial_face_search.py</code> <pre><code>def serial_face_recognition(known_image_path, folder_path, find_all=True, save_results=False):\n    \"\"\"\n    Provided logic wrapped in a function for benchmarking.\n    \"\"\"\n    start = time.time()\n\n    # Load the known face image and get the features of the face\n    known_image = face_recognition.load_image_file(known_image_path)\n    known_encoding = face_recognition.face_encodings(known_image)[0]\n\n    # Get all image files\n    filenames = [file.name for file in os.scandir(folder_path) if file.is_file()]\n\n    matches = []\n\n    for filename in filenames:\n        # Load the unknown face image\n        unknown_image = face_recognition.load_image_file(os.path.join(folder_path, filename))\n\n        # Find faces and encodings in the unknown image\n        unknown_encodings = face_recognition.face_encodings(unknown_image)\n\n        for unknown_encoding in unknown_encodings:\n            # Compare the unknown face encoding with the known encoding\n            result = face_recognition.compare_faces([known_encoding], unknown_encoding)\n\n            if result[0]:  # if a match is found\n                print(\"Match found! in \" + filename)\n                matches.append(filename)\n\n                if save_results:\n                    show_found_image(unknown_image, filename)\n\n                # break out of the face loop if one is found in this image\n                break\n\n        # benchmark logic: early exit if find_all is False\n        if not find_all and matches:\n            break\n\n    time_taken = time.time() - start\n    return matches, time_taken\n</code></pre>"},{"location":"serial_face_search/#serial_face_search.show_found_image","title":"show_found_image","text":"<pre><code>show_found_image(\n    unknown_image, filename, output_dir=\"found_by_serial\"\n)\n</code></pre> <p>Refactored from original: Now it save the found image instead of using cv2.imshow to display I have done this to ensure it works in my wsl headless environment.</p> Source code in <code>serial_face_search.py</code> <pre><code>def show_found_image(unknown_image, filename, output_dir=\"found_by_serial\"):\n    \"\"\"\n    Refactored from original: Now it save the found image instead of using cv2.imshow to display\n    I have done this to ensure it works in my wsl headless environment.\n    \"\"\"\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    face_locations = face_recognition.face_locations(unknown_image)\n\n    # convert RGB (face_recognition) to BGR (OpenCV)\n    output_image = cv2.cvtColor(unknown_image, cv2.COLOR_RGB2BGR)\n\n    # draw rectangles around faces\n    for top, right, bottom, left in face_locations:\n        cv2.rectangle(output_image, (left, top), (right, bottom), (0, 255, 0), 2)\n\n    # logic update: Save the image\n    save_path = os.path.join(output_dir, f\"found_{filename}\")\n    cv2.imwrite(save_path, output_image)\n</code></pre>"},{"location":"utils/","title":"Utils Module","text":""},{"location":"utils/#utils","title":"utils","text":"<p>Utility functions for parallel face recognition</p>"},{"location":"utils/#utils.FaceCache","title":"FaceCache","text":"<p>Cache system for face encodings and locations</p> <p>Time Complexity: O(1) for cache hits, O(n) for cache misses Space Complexity: O(n) where n = number of cached images</p> Explanation <p>Stores face locations and encodings to disk to avoid recomputation Uses pickle for serialization and MD5 hashes for cache validation</p> Source code in <code>utils.py</code> <pre><code>class FaceCache:\n    \"\"\"\n    Cache system for face encodings and locations\n\n    Time Complexity: O(1) for cache hits, O(n) for cache misses\n    Space Complexity: O(n) where n = number of cached images\n\n    Explanation:\n        Stores face locations and encodings to disk to avoid recomputation\n        Uses pickle for serialization and MD5 hashes for cache validation\n    \"\"\"\n\n    def __init__(self, cache_dir=\".face_cache\"):\n        \"\"\"\n        Initialize cache\n\n        Args:\n            cache_dir: directory to store cache files\n        \"\"\"\n        self.cache_dir = cache_dir\n        if not os.path.exists(cache_dir):\n            os.makedirs(cache_dir)\n\n    def _get_cache_path(self, image_path):\n        \"\"\"Get cache file path for given image\"\"\"\n        filename = os.path.basename(image_path)\n        cache_filename = f\"{filename}.cache\"\n        return os.path.join(self.cache_dir, cache_filename)\n\n    def get(self, image_path):\n        \"\"\"\n        Get cached face data\n\n        Args:\n            image_path: path to image file\n\n        Returns:\n            dict with 'locations' and 'encodings', or None if not cached/invalid\n\n        Explanation:\n            Validates cache using file hash to ensure image hasn't changed\n        \"\"\"\n        cache_path = self._get_cache_path(image_path)\n\n        if not os.path.exists(cache_path):\n            return None\n\n        try:\n            with open(cache_path, 'rb') as f:\n                cached_data = pickle.load(f)\n\n            # validate cache using file hash\n            current_hash = get_file_hash(image_path)\n            if cached_data.get('hash') != current_hash:\n                # image changed, cache invalid\n                return None\n\n            return {\n                'locations': cached_data['locations'],\n                'encodings': cached_data['encodings']\n            }\n\n        except Exception:\n            return None\n\n    def set(self, image_path, locations, encodings):\n        \"\"\"\n        Store face data in cache\n\n        Args:\n            image_path: path to image file\n            locations: face locations from face_recognition\n            encodings: face encodings from face_recognition\n\n        Explanation:\n            Stores both data and file hash for validation\n        \"\"\"\n        cache_path = self._get_cache_path(image_path)\n\n        try:\n            cache_data = {\n                'hash': get_file_hash(image_path),\n                'locations': locations,\n                'encodings': encodings\n            }\n\n            with open(cache_path, 'wb') as f:\n                pickle.dump(cache_data, f)\n\n        except Exception as e:\n            print(f\"Warning: Failed to cache {image_path}: {e}\")\n\n    def clear(self):\n        \"\"\"Clear all cache files\"\"\"\n        try:\n            for filename in os.listdir(self.cache_dir):\n                filepath = os.path.join(self.cache_dir, filename)\n                if os.path.isfile(filepath):\n                    os.remove(filepath)\n            print(f\"Cache cleared: {self.cache_dir}\")\n        except Exception as e:\n            print(f\"Error clearing cache: {e}\")\n</code></pre>"},{"location":"utils/#utils.FaceCache.__init__","title":"__init__","text":"<pre><code>__init__(cache_dir='.face_cache')\n</code></pre> <p>Initialize cache</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <p>directory to store cache files</p> <code>'.face_cache'</code> Source code in <code>utils.py</code> <pre><code>def __init__(self, cache_dir=\".face_cache\"):\n    \"\"\"\n    Initialize cache\n\n    Args:\n        cache_dir: directory to store cache files\n    \"\"\"\n    self.cache_dir = cache_dir\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n</code></pre>"},{"location":"utils/#utils.FaceCache.clear","title":"clear","text":"<pre><code>clear()\n</code></pre> <p>Clear all cache files</p> Source code in <code>utils.py</code> <pre><code>def clear(self):\n    \"\"\"Clear all cache files\"\"\"\n    try:\n        for filename in os.listdir(self.cache_dir):\n            filepath = os.path.join(self.cache_dir, filename)\n            if os.path.isfile(filepath):\n                os.remove(filepath)\n        print(f\"Cache cleared: {self.cache_dir}\")\n    except Exception as e:\n        print(f\"Error clearing cache: {e}\")\n</code></pre>"},{"location":"utils/#utils.FaceCache.get","title":"get","text":"<pre><code>get(image_path)\n</code></pre> <p>Get cached face data</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <p>path to image file</p> required <p>Returns:</p> Type Description <p>dict with 'locations' and 'encodings', or None if not cached/invalid</p> Explanation <p>Validates cache using file hash to ensure image hasn't changed</p> Source code in <code>utils.py</code> <pre><code>def get(self, image_path):\n    \"\"\"\n    Get cached face data\n\n    Args:\n        image_path: path to image file\n\n    Returns:\n        dict with 'locations' and 'encodings', or None if not cached/invalid\n\n    Explanation:\n        Validates cache using file hash to ensure image hasn't changed\n    \"\"\"\n    cache_path = self._get_cache_path(image_path)\n\n    if not os.path.exists(cache_path):\n        return None\n\n    try:\n        with open(cache_path, 'rb') as f:\n            cached_data = pickle.load(f)\n\n        # validate cache using file hash\n        current_hash = get_file_hash(image_path)\n        if cached_data.get('hash') != current_hash:\n            # image changed, cache invalid\n            return None\n\n        return {\n            'locations': cached_data['locations'],\n            'encodings': cached_data['encodings']\n        }\n\n    except Exception:\n        return None\n</code></pre>"},{"location":"utils/#utils.FaceCache.set","title":"set","text":"<pre><code>set(image_path, locations, encodings)\n</code></pre> <p>Store face data in cache</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <p>path to image file</p> required <code>locations</code> <p>face locations from face_recognition</p> required <code>encodings</code> <p>face encodings from face_recognition</p> required Explanation <p>Stores both data and file hash for validation</p> Source code in <code>utils.py</code> <pre><code>def set(self, image_path, locations, encodings):\n    \"\"\"\n    Store face data in cache\n\n    Args:\n        image_path: path to image file\n        locations: face locations from face_recognition\n        encodings: face encodings from face_recognition\n\n    Explanation:\n        Stores both data and file hash for validation\n    \"\"\"\n    cache_path = self._get_cache_path(image_path)\n\n    try:\n        cache_data = {\n            'hash': get_file_hash(image_path),\n            'locations': locations,\n            'encodings': encodings\n        }\n\n        with open(cache_path, 'wb') as f:\n            pickle.dump(cache_data, f)\n\n    except Exception as e:\n        print(f\"Warning: Failed to cache {image_path}: {e}\")\n</code></pre>"},{"location":"utils/#utils.calculate_optimal_workers","title":"calculate_optimal_workers","text":"<pre><code>calculate_optimal_workers(\n    total_files, max_workers=None, min_files_per_worker=12\n)\n</code></pre> <p>Calculate optimal number of workers based on workload</p> <p>Parameters:</p> Name Type Description Default <code>total_files</code> <p>total number of files to process</p> required <code>max_workers</code> <p>maximum workers to use (None = auto)</p> <code>None</code> <code>min_files_per_worker</code> <p>minimum files each worker should handle</p> <code>12</code> <p>Returns:</p> Type Description <p>suitable worker count</p> Explanation <p>Reserve one core for main process to avoid oversubscription Oversubscription = creating more threads than physical cores</p> Source code in <code>utils.py</code> <pre><code>def calculate_optimal_workers(total_files, max_workers=None, min_files_per_worker=12):\n    \"\"\"\n    Calculate optimal number of workers based on workload\n\n    Args:\n        total_files: total number of files to process\n        max_workers: maximum workers to use (None = auto)\n        min_files_per_worker: minimum files each worker should handle\n\n    Returns:\n        suitable worker count\n\n    Explanation:\n        Reserve one core for main process to avoid oversubscription\n        Oversubscription = creating more threads than physical cores\n    \"\"\"\n    available_cores = get_cpu_count()\n    usable_cores = max(1, available_cores - 1)  # reserve 1 for main process\n\n    if max_workers is not None:\n        usable_cores = min(usable_cores, max_workers)\n\n    # calculate based on workload\n    # ensure each worker has meaningful work to do\n    optimal_for_workload = max(1, total_files // min_files_per_worker)\n\n    # choose the smaller - either CPU limit or workload-appropriate\n    optimal = min(usable_cores, optimal_for_workload)\n\n    # for very small datasets, use fewer workers\n    if total_files &lt;= 5:\n        optimal = min(2, optimal)\n\n    return max(1, optimal)\n</code></pre>"},{"location":"utils/#utils.chunk_list","title":"chunk_list","text":"<pre><code>chunk_list(lst, n)\n</code></pre> <p>Split list into n roughly equal chunks</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <p>list to split</p> required <code>n</code> <p>number of chunks</p> required <p>Returns:</p> Type Description <p>List of chunks</p> Explanation <p>Load-balanced chunking - distributes items as evenly as possible Example: 10 items, 3 workers - [4, 3, 3] instead of [3, 3, 4]</p> Source code in <code>utils.py</code> <pre><code>def chunk_list(lst, n):\n    \"\"\"\n    Split list into n roughly equal chunks\n\n    Args:\n        lst: list to split\n        n: number of chunks\n\n    Returns:\n        List of chunks\n\n    Explanation:\n        Load-balanced chunking - distributes items as evenly as possible\n        Example: 10 items, 3 workers - [4, 3, 3] instead of [3, 3, 4]\n    \"\"\"\n    if n &lt;= 0:\n        return []\n    if n &gt;= len(lst):\n        # more workers than items, return one item per chunk\n        return [[item] for item in lst]\n\n    chunk_size = len(lst) // n\n    remainder = len(lst) % n\n\n    chunks = []\n    start = 0\n\n    for i in range(n):\n        # first 'remainder' chunks get an extra item\n        end = start + chunk_size + (1 if i &lt; remainder else 0)\n        chunks.append(lst[start:end])\n        start = end\n\n    return chunks\n</code></pre>"},{"location":"utils/#utils.format_time","title":"format_time","text":"<pre><code>format_time(seconds)\n</code></pre> <p>Format seconds into human-readable time string</p> <p>Parameters:</p> Name Type Description Default <code>seconds</code> <p>time in seconds</p> required <p>Returns:</p> Type Description <p>Formatted string (e.g., \"2m 15s\" or \"45.2s\")</p> Source code in <code>utils.py</code> <pre><code>def format_time(seconds):\n    \"\"\"\n    Format seconds into human-readable time string\n\n    Args:\n        seconds: time in seconds\n\n    Returns:\n        Formatted string (e.g., \"2m 15s\" or \"45.2s\")\n    \"\"\"\n    if seconds &gt;= 60:\n        minutes = int(seconds // 60)\n        secs = seconds % 60\n        return f\"{minutes}m {secs:.1f}s\"\n    else:\n        return f\"{seconds:.2f}s\"\n</code></pre>"},{"location":"utils/#utils.get_cpu_count","title":"get_cpu_count","text":"<pre><code>get_cpu_count()\n</code></pre> <p>Get number of available CPU cores</p> <p>Returns:</p> Type Description <p>Number of CPU cores</p> Explanation <p>Use multiprocessing's cpu count to detect hardware threads Important for determining parallel capacity</p> Source code in <code>utils.py</code> <pre><code>def get_cpu_count():\n    \"\"\"\n    Get number of available CPU cores\n\n    Returns:\n        Number of CPU cores\n\n    Explanation:\n        Use multiprocessing's cpu count to detect hardware threads\n        Important for determining parallel capacity\n    \"\"\"\n    return mp.cpu_count()\n</code></pre>"},{"location":"utils/#utils.get_file_hash","title":"get_file_hash","text":"<pre><code>get_file_hash(filepath)\n</code></pre> <p>Calculate MD5 hash of file for cache key</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <p>path to file</p> required <p>Returns:</p> Type Description <p>MD5 hash string</p> Explanation <p>Used to detect if image has changed since last cache Only first 8KB is hashed for speed (sufficient for detection)</p> Source code in <code>utils.py</code> <pre><code>def get_file_hash(filepath):\n    \"\"\"\n    Calculate MD5 hash of file for cache key\n\n    Args:\n        filepath: path to file\n\n    Returns:\n        MD5 hash string\n\n    Explanation:\n        Used to detect if image has changed since last cache\n        Only first 8KB is hashed for speed (sufficient for detection)\n    \"\"\"\n    hash_md5 = hashlib.md5()\n    try:\n        with open(filepath, \"rb\") as f:\n            # read first 8KB for speed\n            chunk = f.read(8192)\n            hash_md5.update(chunk)\n        return hash_md5.hexdigest()\n    except Exception:\n        return None\n</code></pre>"},{"location":"utils/#utils.validate_image_path","title":"validate_image_path","text":"<pre><code>validate_image_path(path)\n</code></pre> <p>Validate if path is valid image file</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if valid</p> Source code in <code>utils.py</code> <pre><code>def validate_image_path(path):\n    \"\"\"\n    Validate if path is valid image file\n\n    Returns:\n        bool: True if valid\n    \"\"\"\n    if not os.path.exists(path):\n        return False\n\n    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n    _, ext = os.path.splitext(path.lower())\n\n    return ext in valid_extensions\n</code></pre>"}]}